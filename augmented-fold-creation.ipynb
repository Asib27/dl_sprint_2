{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip install -q pycocotools","metadata":{"_uuid":"97891a81-936e-489b-8e11-e3570c15ef88","_cell_guid":"d8cc3724-9f69-42c8-90f2-f76f29572a4d","collapsed":false,"execution":{"iopub.status.busy":"2023-08-04T07:59:44.854804Z","iopub.execute_input":"2023-08-04T07:59:44.855231Z","iopub.status.idle":"2023-08-04T08:00:28.940361Z","shell.execute_reply.started":"2023-08-04T07:59:44.855197Z","shell.execute_reply":"2023-08-04T08:00:28.938899Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\n\nimport pandas as pd\nfrom pycocotools.coco import COCO\nfrom sklearn.model_selection import StratifiedGroupKFold\nfrom tqdm.notebook import tqdm","metadata":{"_uuid":"3e48c636-3ef2-47ff-8ef9-f7c3d4243572","_cell_guid":"365653d9-1893-4fed-b260-ab1fbede4df8","collapsed":false,"execution":{"iopub.status.busy":"2023-08-04T08:00:28.943182Z","iopub.execute_input":"2023-08-04T08:00:28.943659Z","iopub.status.idle":"2023-08-04T08:00:29.825169Z","shell.execute_reply.started":"2023-08-04T08:00:28.943615Z","shell.execute_reply":"2023-08-04T08:00:29.824156Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CFG:\n    n_splits = 4\n    fold = 0 # change this parameter to create separate folds\n    seed = 3000","metadata":{"_uuid":"b3264b60-0780-4b97-8239-3339ab438d61","_cell_guid":"e9ff3a4b-da68-4de1-862d-d805b9c6fbfc","collapsed":false,"execution":{"iopub.status.busy":"2023-08-04T08:00:29.826889Z","iopub.execute_input":"2023-08-04T08:00:29.827909Z","iopub.status.idle":"2023-08-04T08:00:29.833608Z","shell.execute_reply.started":"2023-08-04T08:00:29.827868Z","shell.execute_reply":"2023-08-04T08:00:29.832343Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"coco = COCO(\"../input/dlsprint2/badlad/labels/coco_format/train/badlad-train-coco.json\")\nsgkf = StratifiedGroupKFold(n_splits=CFG.n_splits, shuffle=True, random_state=CFG.seed)","metadata":{"_uuid":"156a0c39-0158-4040-b6a9-bcddd0b33d7a","_cell_guid":"6124f9f8-3289-4b45-9bac-8ba6d75b7b08","collapsed":false,"execution":{"iopub.status.busy":"2023-08-04T08:00:29.836595Z","iopub.execute_input":"2023-08-04T08:00:29.836926Z","iopub.status.idle":"2023-08-04T08:00:37.717564Z","shell.execute_reply.started":"2023-08-04T08:00:29.836900Z","shell.execute_reply":"2023-08-04T08:00:37.716412Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ann_ids = coco.getAnnIds()\nanns = coco.loadAnns(ann_ids)\n\ncat_ids = [ann[\"category_id\"] for ann in anns]\nimg_ids = [ann[\"image_id\"] for ann in anns]\n\nann_ids = pd.Series(ann_ids)\ncat_ids = pd.Series(cat_ids)\nimg_ids = pd.Series(img_ids)","metadata":{"_uuid":"402ea7e0-b662-488d-82fd-4f8c18a9e27c","_cell_guid":"d09b47a8-defc-4f14-bee6-8769f2546501","collapsed":false,"execution":{"iopub.status.busy":"2023-08-04T08:00:37.718920Z","iopub.execute_input":"2023-08-04T08:00:37.719382Z","iopub.status.idle":"2023-08-04T08:00:38.758241Z","shell.execute_reply.started":"2023-08-04T08:00:37.719352Z","shell.execute_reply":"2023-08-04T08:00:38.757337Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"indices = [val_idx for _, val_idx in sgkf.split(ann_ids, cat_ids, img_ids)]\nfold_idx = indices[CFG.fold]\nval_img_ids = set(img_ids[fold_idx])","metadata":{"_uuid":"d3cb624d-9632-4e4a-9331-7f8007bd0d77","_cell_guid":"00201dec-cabb-40bc-9903-6e2e07641cfe","collapsed":false,"execution":{"iopub.status.busy":"2023-08-04T08:00:38.759912Z","iopub.execute_input":"2023-08-04T08:00:38.760271Z","iopub.status.idle":"2023-08-04T08:00:47.456385Z","shell.execute_reply.started":"2023-08-04T08:00:38.760236Z","shell.execute_reply":"2023-08-04T08:00:47.455225Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_ids = coco.getCatIds()\ncats = coco.loadCats(cat_ids)\ncat_names = [cat[\"name\"] for cat in cats]\n\nfor cat_id, cat_name in zip(cat_ids, cat_names):\n    ids = coco.getImgIds(imgIds=val_img_ids, catIds=[cat_id])\n    print(f\"Number of Images Containing {cat_name}: {len(ids)}\")","metadata":{"_uuid":"65f4e465-8328-4f37-8a23-3b1f8d295f91","_cell_guid":"d70bd004-ce04-4c00-beb9-f4849e0532d8","collapsed":false,"execution":{"iopub.status.busy":"2023-08-04T08:00:47.457749Z","iopub.execute_input":"2023-08-04T08:00:47.458106Z","iopub.status.idle":"2023-08-04T08:00:47.517484Z","shell.execute_reply.started":"2023-08-04T08:00:47.458074Z","shell.execute_reply":"2023-08-04T08:00:47.516263Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Augmentation Utils","metadata":{"_uuid":"5b35126e-ce48-455c-b385-3bdc1a95d892","_cell_guid":"c3a90ebf-44db-4a3e-8823-4bc05d0f9ed7","trusted":true}},{"cell_type":"code","source":"# ---------------------------------------------------------\n# Copyright (c) Microsoft Corporation. All rights reserved.\n# Licensed under the MIT License.\n# ---------------------------------------------------------\n\nfrom math import floor\n\nimport cv2\nimport numpy as np\nimport random\n\n\ndef blur(src, radius=5):\n    \"\"\"Wrapper function for cv2.GaussianBlur\n\n    Arguments:\n        src (numpy.ndarray) : source image of shape (rows, cols)\n        radius (int, optional) : size of the square kernel, MUST be an odd integer.\n                                 Defaults to 5.\n\n    Returns:\n        numpy.ndarray: a copy of the source image after apply the effect\n    \"\"\"\n    return cv2.GaussianBlur(src, (radius, radius), cv2.BORDER_DEFAULT)\n\n\ndef overlay_weighted(src, background, alpha, beta, gamma=0):\n    \"\"\"overlay two images together, pixels from each image is weighted as follow\n\n        dst[i] = alpha*src[i] + beta*background[i] + gamma\n\n    Arguments:\n        src (numpy.ndarray) : source image of shape (rows, cols)\n        background (numpy.ndarray) : background image. Must be in same shape are `src`\n        alpha (float) : transparent factor for the foreground\n        beta (float) : transparent factor for the background\n        gamma (int, optional) : luminance constant. Defaults to 0.\n\n    Returns:\n        numpy.ndarray: a copy of the source image after apply the effect\n    \"\"\"\n    return cv2.addWeighted(src, alpha, background, beta, gamma).astype(np.uint8)\n\n\ndef overlay(src, background):\n    \"\"\"Overlay two images together via bitwise-and:\n\n        dst[i] = src[i] & background[i]\n\n    Arguments:\n        src (numpy.ndarray) : source image of shape (rows, cols)\n        background (numpy.ndarray) : background image. Must be in same shape are `src`\n\n    Returns:\n        numpy.ndarray: a copy of the source image after apply the effect\n    \"\"\"\n    return cv2.bitwise_and(src, background).astype(np.uint8)\n\n\ndef translation(src, offset_x, offset_y):\n    \"\"\"Shift the image in x, y direction\n\n    Arguments:\n        src (numpy.ndarray) : source image of shape (rows, cols)\n        offset_x (int) : pixels in the x direction.\n                          Positive value shifts right and negative shifts right.\n        offset_y (int) : pixels in the y direction.\n                          Positive value shifts down and negative shifts up.\n\n    Returns:\n        numpy.ndarray: a copy of the source image after apply the effect\n    \"\"\"\n    rows, cols = src.shape[:2]\n    trans_matrix = np.float32([[1, 0, offset_x], [0, 1, offset_y]])\n    # size of the output image should be in the form of (width, height)\n    dst = cv2.warpAffine(src, trans_matrix, (cols, rows), borderValue=255)\n    return dst.astype(np.uint8)\n\n\ndef bleed_through(src, background=None, alpha=0.8, gamma=0, offset_x=0, offset_y=5):\n    \"\"\"Apply bleed through effect, background is flipped horizontally.\n\n    Arguments:\n        src (numpy.ndarray) : source image of shape (rows, cols)\n        background (numpy.ndarray, optional) : background image. Must be in same\n                                               shape as foreground. Defaults to None.\n        alpha (float, optional) : transparent factor for the foreground. Defaults to 0.8.\n        gamma (int, optional) : luminance constant. Defaults to 0.\n        offset_x (int, optional) : background translation offset. Defaults to 0.\n                                   Positive value shifts right and negative shifts right.\n        offset_y (int, optional) : background translation offset. Defaults to 5.\n                                   Positive value shifts down and negative shifts up.\n\n    Returns:\n        numpy.ndarray: a copy of the source image after apply the effect. Pixel value ranges [0, 255]\n    \"\"\"\n    if background is None:\n        background = src.copy()\n    background = cv2.flip(background, 1)  # flipped horizontally\n    background = translation(background, offset_x, offset_y)\n    beta = 1 - alpha\n    return overlay_weighted(src, background, alpha, beta, gamma)\n\n\ndef pepper(src, amount=0.05):\n    \"\"\"Randomly sprinkle dark pixels on src image.\n    Wrapper function for skimage.util.noise.random_noise().\n    See https://scikit-image.org/docs/stable/api/skimage.util.html#random-noise\n\n    Arguments:\n        src (numpy.ndarray) : source image of shape (rows, cols)\n        amount (float, optional) : proportion of pixels in range [0, 1] to apply the effect.\n                                   Defaults to 0.05.\n\n    Returns:\n        numpy.ndarray: a copy of the source image after apply the effect.\n        Pixel value ranges [0, 255] as uint8.\n    \"\"\"\n    dst = src.copy()\n    # Method returns random floats in uniform distribution [0, 1)\n    noise = np.random.random(src.shape)\n    dst[noise < amount] = 0\n    return dst.astype(np.uint8)\n\n\ndef salt(src, amount=0.3):\n    \"\"\"Randomly sprinkle white pixels on src image.\n    Wrapper function for skimage.util.noise.random_noise().\n    See https://scikit-image.org/docs/stable/api/skimage.util.html#random-noise\n\n    Arguments:\n        src (numpy.ndarray) : source image of shape (rows, cols)\n        amount (float, optional) : proportion of pixels in range [0, 1] to apply the effect.\n                                   Defaults to 0.05.\n\n    Returns:\n        numpy.ndarray: a copy of the source image after apply the effect.\n        Pixel value ranges [0, 255]\n    \"\"\"\n    dst = src.copy()\n    # Method returns random floats in uniform distribution [0, 1)\n    noise = np.random.random(src.shape)\n    dst[noise < amount] = 255\n    return dst.astype(np.uint8)\n\n\ndef salt_then_pepper(src, salt_amount=0.1, pepper_amount=0.05):\n    \"\"\"Randomly add salt then add pepper onto the image.\n\n    Arguments:\n        src (numpy.ndarray) : source image of shape (rows, cols)\n        salt_amount (float) : proportion of pixels in range [0, 1] to\n                              apply the salt effect.\n                              Defaults to 0.1.\n        pepper_amount (float) : proportion of pixels in range [0, 1] to\n                                apply the pepper effect.\n                                Defaults to 0.05.\n\n    Returns:\n        numpy.ndarray: a copy of the source image after apply the effect.\n        Pixel value ranges [0, 255] as uint8.\n    \"\"\"\n    salted = salt(src, amount=salt_amount)\n    return pepper(salted, amount=pepper_amount)\n\n\ndef pepper_then_salt(src, pepper_amount=0.05, salt_amount=0.1):\n    \"\"\"Randomly add pepper then salt onto the image.\n\n    Arguments:\n        src (numpy.ndarray) : source image of shape (rows, cols)\n        pepper_amount (float) : proportion of pixels in range [0, 1] to\n                                apply the pepper effect.\n                                Defaults to 0.05.\n        salt_amount (float) : proportion of pixels in range [0, 1] to\n                              apply the salt effect.\n                              Defaults to 0.1.\n\n    Returns:\n        numpy.ndarray: a copy of the source image after apply the effect.\n        Pixel value ranges [0, 255] as uint8.\n    \"\"\"\n    peppered = pepper(src, amount=pepper_amount)\n    return salt(peppered, amount=salt_amount)\n\n\ndef create_2D_kernel(kernel_shape, kernel_type=\"ones\"):\n    \"\"\"Create 2D kernel for morphological operations.\n\n    Arguments:\n        kernel_shape (tuple) : shape of the kernel (rows, cols)\n        kernel_type (str, optional) : type of kernel. Defaults to \"ones\".\n    ::\n\n        All supported kernel types are below:\n\n        \"ones\": kernel is filled with all 1s in shape (rows, cols)\n                    [[1,1,1],\n                    [1,1,1],\n                    [1,1,1]]\n        \"upper_triangle\": upper triangular matrix filled with ones\n                    [[1,1,1],\n                    [0,1,1],\n                    [0,0,1]]\n        \"lower_triangle\": lower triangular matrix filled with ones\n                    [[1,0,0],\n                    [1,1,0],\n                    [1,1,1]]\n        \"x\": \"X\" shape cross\n                    [[1,0,1],\n                    [0,1,0],\n                    [1,0,1]]\n        \"plus\": \"+\" shape cross\n                    [[0,1,0],\n                    [1,1,1],\n                    [0,1,0]]\n        \"ellipse\": elliptical kernel\n                    [[0, 0, 1, 0, 0],\n                    [1, 1, 1, 1, 1],\n                    [1, 1, 1, 1, 1],\n                    [1, 1, 1, 1, 1],\n                    [0, 0, 1, 0, 0]]\n\n    Raises:\n        ValueError: if kernel is not a 2-element tuple or\n                    kernel_type is not one of the supported values\n\n    Returns:\n        numpy.ndarray: a 2D array of shape `kernel_shape`.\n    \"\"\"\n    if len(kernel_shape) != 2:\n        raise ValueError(\"Kernel shape must be a tuple of 2 integers\")\n    kernel_rows, kernel_cols = kernel_shape\n    if kernel_type == \"ones\":\n        kernel = np.ones(kernel_shape)\n    elif kernel_type == \"upper_triangle\":\n        kernel = np.triu(np.ones(kernel_shape))\n    elif kernel_type == \"lower_triangle\":\n        kernel = np.tril(np.ones(kernel_shape))\n    elif kernel_type == \"x\":\n        diagonal = np.eye(kernel_rows, kernel_cols)\n        kernel = np.add(diagonal, np.fliplr(diagonal))\n        kernel[kernel > 1] = 1\n    elif kernel_type == \"plus\":\n        kernel = np.zeros(kernel_shape)\n        center_col = floor(kernel.shape[0] / 2)\n        center_row = floor(kernel.shape[1] / 2)\n        kernel[:, center_col] = 1\n        kernel[center_row, :] = 1\n    elif kernel_type == \"ellipse\":\n        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, kernel_shape)\n    else:\n        valid_kernel_types = {\n            \"ones\",\n            \"upper_triangle\",\n            \"lower_triangle\",\n            \"x\",\n            \"plus\",\n            \"ellipse\",\n        }\n        raise ValueError(\n            f\"Invalid kernel_type: {kernel_type}. Valid types are {valid_kernel_types}\"\n        )\n\n    return kernel.astype(np.uint8)\n\n\ndef morphology(src, operation=\"open\", kernel_shape=(3, 3), kernel_type=\"ones\"):\n    \"\"\"Dynamic calls different morphological operations\n    (\"open\", \"close\", \"dilate\" and \"erode\") with the given parameters\n\n    Arguments:\n        src (numpy.ndarray) : source image of shape (rows, cols)\n        operation (str, optional) : name of a morphological operation:\n                                    ``(\"open\", \"close\", \"dilate\", \"erode\")``\n                                    Defaults to ``\"open\"``.\n        kernel_shape (tuple, optional) : shape of the kernel (rows, cols).\n                                         Defaults to (3,3).\n        kernel_type (str, optional) : type of kernel.\n            ``(\"ones\", \"upper_triangle\", \"lower_triangle\", \"x\", \"plus\", \"ellipse\")``\n            Defaults to ``\"ones\"``.\n\n    Returns:\n        numpy.ndarray: a copy of the source image after apply the effect.\n    \"\"\"\n    kernel = create_2D_kernel(kernel_shape, kernel_type)\n    if operation == \"open\":\n        return open(src, kernel)\n    elif operation == \"close\":\n        return close(src, kernel)\n    elif operation == \"dilate\":\n        return dilate(src, kernel)\n    elif operation == \"erode\":\n        return erode(src, kernel)\n    else:\n        valid_operations = [\"open\", \"close\", \"dilate\", \"erode\"]\n        raise ValueError(\n            f\"Invalid morphology operation '{operation}'. Valid morphological operations are {valid_operations}\"\n        )\n\n\ndef open(src, kernel):\n    \"\"\" \"open\" morphological operation. Like morphological \"erosion\", it removes\n    foreground pixels (white pixels), however it is less destructive than erosion.\n\n    For more information see:\n\n    1. https://docs.opencv.org/master/d9/d61/tutorial_py_morphological_ops.html\n    2. http://homepages.inf.ed.ac.uk/rbf/HIPR2/open.htm\n\n    Arguments:\n        src (numpy.ndarray) : source image of shape (rows, cols)\n        kernel (numpy.ndarray) : a 2D array for structuring the morphological effect\n\n    Returns:\n        numpy.ndarray: a copy of the source image after apply the effect.\n    \"\"\"\n    return cv2.morphologyEx(src, cv2.MORPH_OPEN, kernel)\n\n\ndef close(src, kernel):\n    \"\"\" \"close\" morphological operation. Like morphological \"dilation\", it grows the\n    boundary of the foreground (white pixels), however, it is less destructive than\n    dilation of the original boundary shape.\n\n    For more information see:\n\n    1. https://docs.opencv.org/master/d9/d61/tutorial_py_morphological_ops.html\n    2. http://homepages.inf.ed.ac.uk/rbf/HIPR2/close.htm\n\n    Arguments:\n        src (numpy.ndarray) : source image of shape (rows, cols)\n        kernel (numpy.ndarray) : a 2D array for structuring the morphological effect\n\n    Returns:\n        numpy.ndarray: a copy of the source image after apply the effect.\n    \"\"\"\n    return cv2.morphologyEx(src, cv2.MORPH_CLOSE, kernel)\n\n\ndef erode(src, kernel):\n    \"\"\" \"erode\" morphological operation. Erodes foreground pixels (white pixels).\n\n    For more information see:\n\n    1. https://docs.opencv.org/master/d9/d61/tutorial_py_morphological_ops.html\n    2. http://homepages.inf.ed.ac.uk/rbf/HIPR2/erode.htm\n\n    Arguments:\n        src (numpy.ndarray) : source image of shape (rows, cols)\n        kernel (numpy.ndarray) : a 2D array for structuring the morphological effect\n\n    Returns:\n        numpy.ndarray: a copy of the source image after apply the effect.\n    \"\"\"\n    return cv2.erode(src, kernel)\n\n\ndef dilate(src, kernel):\n    \"\"\" \"dilate\" morphological operation. Grows foreground pixels (white pixels).\n\n    For more information see:\n\n    1. https://docs.opencv.org/master/d9/d61/tutorial_py_morphological_ops.html\n    2. http://homepages.inf.ed.ac.uk/rbf/HIPR2/dilate.htm\n\n    Arguments:\n        src (numpy.ndarray) : source image of shape (rows, cols)\n        kernel (numpy.ndarray) : a 2D array for structuring the morphological effect\n\n    Returns:\n        numpy.ndarray: a copy of the source image after apply the effect.\n    \"\"\"\n    return cv2.dilate(src, kernel)","metadata":{"_uuid":"2288dd65-a9ba-410c-8445-a381ef40b337","_cell_guid":"7c021ad0-72f8-4631-bcc8-6cfda720a3b1","collapsed":false,"execution":{"iopub.status.busy":"2023-08-01T17:17:15.691705Z","iopub.execute_input":"2023-08-01T17:17:15.692433Z","iopub.status.idle":"2023-08-01T17:17:15.767756Z","shell.execute_reply.started":"2023-08-01T17:17:15.692388Z","shell.execute_reply":"2023-08-01T17:17:15.766483Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"effect_prob = {\n    'blur' : .3,\n    'bleed_through': .3,\n    'pepper': .4,\n    'salt': .4,\n    'open': .2,\n    'close': .2,\n    'dilate': .2,\n    'erode': .2\n}\ndef augment(img):\n    if random.random() <= effect_prob['blur']:\n        img = blur(img)\n    if random.random() <= effect_prob['bleed_through']:\n        img = bleed_through(img, alpha=0.8, gamma=0.4, offset_y = 10, offset_x=10)\n    if random.random() <= effect_prob['pepper']:\n        img = pepper(img, .067)\n    if random.random() <= effect_prob['salt']:\n        img = salt(img, .35)\n    if random.random() > effect_prob['open']:\n        img = morphology(img, 'open')\n    if random.random() > effect_prob['close']:\n        img = morphology(img, 'close')\n#     if random.random() > effect_prob['dilate']:\n#         img = morphology(img, 'dilate')\n    if random.random() > effect_prob['erode']:\n        img = morphology(img, 'erode')\n    return img","metadata":{"_uuid":"971d773e-c9f7-4b85-b9c9-5736a568d86f","_cell_guid":"df0d1aee-2331-4351-8577-fd0d766a033c","collapsed":false,"execution":{"iopub.status.busy":"2023-08-01T17:17:37.709516Z","iopub.execute_input":"2023-08-01T17:17:37.710605Z","iopub.status.idle":"2023-08-01T17:17:37.719985Z","shell.execute_reply.started":"2023-08-01T17:17:37.710566Z","shell.execute_reply":"2023-08-01T17:17:37.718837Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! mkdir /kaggle/working/images\n! mkdir /kaggle/working/labels","metadata":{"_uuid":"b39a50b2-9cae-4fe3-81fe-e9520d951480","_cell_guid":"e16db8af-4100-4dfb-a76e-63ec2b6c1f88","collapsed":false,"execution":{"iopub.status.busy":"2023-08-04T08:06:13.884077Z","iopub.execute_input":"2023-08-04T08:06:13.884500Z","iopub.status.idle":"2023-08-04T08:06:16.137875Z","shell.execute_reply.started":"2023-08-04T08:06:13.884470Z","shell.execute_reply":"2023-08-04T08:06:16.136031Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for img in tqdm(coco.loadImgs(val_img_ids)):\n    img_src = \"/kaggle/input/dlsprint2/badlad/images/train/\" + img[\"file_name\"]\n    img_dst = \"/kaggle/working/images/\" + img[\"file_name\"]\n    \n    load_img = cv2.imread(img_src)\n    load_img = augment(load_img)\n    cv2.imwrite(img_dst, load_img)\n    \n    label_src = \"/kaggle/input/dlsprint2/badlad/labels/yolov8_format/train/\" + img[\"file_name\"][:-4] + \".txt\"\n    label_dst = \"/kaggle/working/labels/\" + img[\"file_name\"][:-4] + \".txt\"\n    shutil.copy(label_src, label_dst)","metadata":{"_uuid":"2e3c2ef4-6930-4140-b352-b866b48b2698","_cell_guid":"47271349-62b6-4517-852f-eab8de07172d","collapsed":false,"execution":{"iopub.status.busy":"2023-08-04T08:06:17.874657Z","iopub.execute_input":"2023-08-04T08:06:17.875087Z","iopub.status.idle":"2023-08-04T08:06:19.037002Z","shell.execute_reply.started":"2023-08-04T08:06:17.875051Z","shell.execute_reply":"2023-08-04T08:06:19.035548Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}